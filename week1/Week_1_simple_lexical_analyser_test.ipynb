{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "177c1327",
   "metadata": {},
   "source": [
    "# SIMPLE LEXICAL ANALYSER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9336d8",
   "metadata": {},
   "source": [
    "This is a diary of some personal notes I have found online, Most helpful araticle i hackernoon: https://hackernoon.com/lexical-analysis-861b8bfe4cb0. My interpretation of a lexical analyser is it breaks down some type of information into lexemes, which are just identifiable sequence of characters,symbols and etc. This lexemes depend on the context of information, ie, the lexems for chinese characters are not the same as english lexemes, coding and etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432d2297",
   "metadata": {},
   "source": [
    "A popularily used word is token, token is the object to describe these lexemes for example a token for car,truck and etc is vehicle. a token for mathematical symbols is operators/symbols and etc. these are the tokens also mentioned as regular definition aswell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bcec728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifier -->  In\n",
      "Identifier -->  lexical\n",
      "Identifier -->  a\n",
      "Identifier -->  set\n",
      "Identifier -->  of\n",
      "Identifier -->  symbols\n",
      "Identifier -->  is\n",
      "Identifier -->  crucial\n",
      "Keyword --> for\n",
      "Identifier -->  understanding\n",
      "Identifier -->  and\n",
      "Identifier -->  processing\n",
      "Identifier -->  Keywords\n",
      "Identifier -->  such\n",
      "Identifier -->  as\n",
      "Identifier -->  and\n",
      "Identifier -->  play\n",
      "Identifier -->  a\n",
      "Identifier -->  pivotal\n",
      "Identifier -->  role\n",
      "Identifier -->  in\n",
      "Identifier -->  defining\n",
      "Identifier -->  the\n",
      "Identifier -->  structure\n",
      "Identifier -->  and\n",
      "Identifier -->  logic\n",
      "Identifier -->  of\n",
      "Identifier -->  programming\n",
      "Identifier -->  functions\n",
      "Identifier -->  like\n",
      "Identifier -->  and\n",
      "Identifier -->  provide\n",
      "Identifier -->  essential\n",
      "Identifier -->  functionalities\n",
      "Keyword --> for\n",
      "Identifier -->  input\n",
      "Identifier -->  and\n",
      "Identifier -->  output\n",
      "Identifier -->  Operators\n",
      "Identifier -->  such\n",
      "Identifier -->  as\n",
      "Identifier -->  and\n",
      "Identifier -->  facilitate\n",
      "Identifier -->  mathematical\n",
      "Identifier -->  computations\n",
      "Identifier -->  and\n",
      "Keyword --> while\n",
      "Identifier -->  special\n",
      "Identifier -->  symbols\n",
      "Identifier -->  like\n",
      "Identifier -->  and\n",
      "Identifier -->  add\n",
      "Identifier -->  uniqueness\n",
      "Identifier -->  to\n",
      "Identifier -->  Separators\n",
      "Identifier -->  like\n",
      "Identifier -->  and\n",
      "Identifier -->  aid\n",
      "Identifier -->  in\n",
      "Identifier -->  code\n",
      "Identifier -->  A\n",
      "Identifier -->  comprehensive\n",
      "Identifier -->  understanding\n",
      "Identifier -->  of\n",
      "Identifier -->  these\n",
      "Identifier -->  symbols\n",
      "Identifier -->  is\n",
      "Identifier -->  fundamental\n",
      "Keyword --> for\n",
      "Identifier -->  parsing\n",
      "Identifier -->  and\n",
      "Identifier -->  interpreting\n",
      "Identifier -->  code\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "keyword = ['break','case','char','const','countinue','deafult','do','int','else','enum','extern','float','for','goto','if','long','register','return','short','signed','sizeof','static','switch','typedef','union','unsigned','void','volatile','while']\n",
    "built_in_functions = ['clrscr()','printf(','scanf(','getch()','main()']\n",
    "operators = ['+','-','*','/','%','==','!=','>','<','>=','<=','&&','||','!','&','|','^','~','>>','<<','=','+=','-=','*=']\n",
    "specialsymbol = ['@','#','$','_','!']\n",
    "separator = [',',':',';','\\n','\\t','{','}','(',')','[',']']\n",
    "\n",
    "\n",
    "file = open('lexical.txt','r+')\n",
    "contents = file.read()\n",
    "splitCode = contents.split() #split program in word based on space\n",
    "length = len(splitCode)      # count the number of word in program\n",
    "for i in range(0,length):\n",
    "    if splitCode[i] in keyword:\n",
    "        print(\"Keyword -->\",splitCode[i])\n",
    "        continue\n",
    "    if splitCode[i] in operators:\n",
    "        print(\"Operators --> \",splitCode[i])\n",
    "        continue\n",
    "    if splitCode[i] in specialsymbol:\n",
    "        print(\"Special Operator -->\",splitCode[i])\n",
    "        continue\n",
    "    if splitCode[i] in built_in_functions:\n",
    "        print(\"Built_in Function -->\",splitCode[i])\n",
    "        continue\n",
    "    if splitCode[i] in separator:\n",
    "        print(\"Separator -->\",splitCode[i])\n",
    "        continue\n",
    "    if re.match(r'(#include*).*', splitCode[i]):\n",
    "        print (\"Header File -->\", splitCode[i])\n",
    "        continue\n",
    "    if re.match(r'^[-+]?[0-9]+$',splitCode[i]):\n",
    "        print(\"Numerals --> \",splitCode[i])\n",
    "        continue\n",
    "    if re.match(r\"^[^\\d\\W]\\w*\\Z\", splitCode[i]):\n",
    "        print(\"Identifier --> \",splitCode[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc522fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
